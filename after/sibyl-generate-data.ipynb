{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9Zs0hYFFIYf"
   },
   "source": [
    "## Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t8_koamxFHfR",
    "outputId": "e892403a-70b8-4728-ec18-c31ee7e81580"
   },
   "outputs": [],
   "source": [
    "from sibyl import *\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktCv--paFOqG"
   },
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\Fabrice\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"glue\", \"sst2\", split=\"train[:10000]\")\n",
    "dataset = dataset.rename_column('sentence', 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-n / Bot-n Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = [t[0] for t in [\n",
    "    ('InsertPunctuationMarks', 0.0),\n",
    "    ('HomoglyphSwap', 0.0),\n",
    "    ('AddPositiveEmoji', 0.0),\n",
    "    ('ImportLinkText', 0.0),\n",
    "    ('AddNegativeLink', 0.0),\n",
    "    ('ChangeLocation', 0.0),\n",
    "    ('ExpandContractions', 0.0),\n",
    "    ('ChangeNumber', 0.0),\n",
    "    ('RemovePositiveEmoji', 10.108303249097474),\n",
    "    ('RemoveNegativeEmoji', 18.75321998969603),\n",
    "    ('AddNegativeEmoji', 24.52004041764904),\n",
    "    ('AddNeutralEmoji', 32.76327632763276),\n",
    "    ('ChangeName', 32.76327632763277),\n",
    "    ('Demojify', 32.76327632763277),\n",
    "    ('InsertPositivePhrase', 32.76327632763277),\n",
    "    ('RemoveNeutralEmoji', 32.76327632763277),\n",
    "    ('RemoveNegation', 38.51851851851851),\n",
    "    ('AddPositiveLink', 40.28776978417267),\n",
    "    ('RandomCharSwap', 43.268945022288264),\n",
    "    ('TextMix', 43.627646823811425)\n",
    "]]\n",
    "black_list = [\n",
    "    'Concept2Sentence', \n",
    "    'ConceptMix', \n",
    "    'Emojify', \n",
    "    'ImportLinkText', \n",
    "    'RemovePositiveEmoji', \n",
    "    'RemoveNegativeEmoji', \n",
    "    'RemoveNeutralEmoji'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_classes = [t for t in TRANSFORMATIONS if t.__name__ in top_n and t.__name__ not in black_list] \n",
    "bot_n_classes = [t for t in TRANSFORMATIONS if t.__name__ not in top_n and t.__name__ not in black_list] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sibyl Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_transformer = SibylTransformer(\"sentiment\", transforms=top_n_classes)\n",
    "bot_n_transformer = SibylTransformer(\"sentiment\", transforms=bot_n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text, new_labels = [], []\n",
    "for batch in batcher(dataset, 10):\n",
    "    t_, l_ = top_n_transformer((batch['text'], batch['label']))\n",
    "    new_text.extend(t_)\n",
    "    new_labels.extend(l_)\n",
    "    \n",
    "df = pd.DataFrame([new_text, new_labels]).T\n",
    "df.columns = ['text', 'label']\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.to_csv('sst2_sibyl_train_top_16.csv')\n",
    "\n",
    "new_text, new_labels = [], []\n",
    "for batch in batcher(dataset, 10):\n",
    "    t_, l_ = bot_n_transformer((batch['text'], batch['label']))\n",
    "    new_text.extend(t_)\n",
    "    new_labels.extend(l_)\n",
    "    \n",
    "df = pd.DataFrame([new_text, new_labels]).T\n",
    "df.columns = ['text', 'label']\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.to_csv('sst2_sibyl_train_bot_16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dpml",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
