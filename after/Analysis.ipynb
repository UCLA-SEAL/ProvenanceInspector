{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4bb3fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33077d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pth = './results_a2t_sst2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2cdf0387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>perturbed_text</th>\n",
       "      <th>result_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it 's a charming and often affecting journey .</td>\n",
       "      <td>it 's a charming and normally affecting journe...</td>\n",
       "      <td>Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unflinchingly bleak and desperate</td>\n",
       "      <td>unflinchingly grim and desperate</td>\n",
       "      <td>Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allows us to hope that nolan is poised to emba...</td>\n",
       "      <td>authorizes us to hopes that nolan is prepped t...</td>\n",
       "      <td>Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the acting , costumes , music , cinematography...</td>\n",
       "      <td>the acting , costumes , music , cinematography...</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it 's slow -- very , very slow .</td>\n",
       "      <td>it 's slow -- very , very slower .</td>\n",
       "      <td>Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>has all the depth of a wading pool .</td>\n",
       "      <td>has all the depths of a wading pool .</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>a movie with a real anarchic flair .</td>\n",
       "      <td>a films with a true anarchic flair .</td>\n",
       "      <td>Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>a subject like this should inspire reaction in...</td>\n",
       "      <td>a subject like this should inspiring reply in ...</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>... is an arthritic attempt at directing by ca...</td>\n",
       "      <td>... is an arthritic endeavour at directing by ...</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>looking aristocratic , luminous yet careworn i...</td>\n",
       "      <td>looking aristocratic , luminous yet careworn i...</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>872 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         original_text  \\\n",
       "0      it 's a charming and often affecting journey .    \n",
       "1                   unflinchingly bleak and desperate    \n",
       "2    allows us to hope that nolan is poised to emba...   \n",
       "3    the acting , costumes , music , cinematography...   \n",
       "4                    it 's slow -- very , very slow .    \n",
       "..                                                 ...   \n",
       "867              has all the depth of a wading pool .    \n",
       "868              a movie with a real anarchic flair .    \n",
       "869  a subject like this should inspire reaction in...   \n",
       "870  ... is an arthritic attempt at directing by ca...   \n",
       "871  looking aristocratic , luminous yet careworn i...   \n",
       "\n",
       "                                        perturbed_text result_type  \n",
       "0    it 's a charming and normally affecting journe...      Failed  \n",
       "1                    unflinchingly grim and desperate       Failed  \n",
       "2    authorizes us to hopes that nolan is prepped t...      Failed  \n",
       "3    the acting , costumes , music , cinematography...  Successful  \n",
       "4                  it 's slow -- very , very slower .       Failed  \n",
       "..                                                 ...         ...  \n",
       "867             has all the depths of a wading pool .   Successful  \n",
       "868              a films with a true anarchic flair .       Failed  \n",
       "869  a subject like this should inspiring reply in ...  Successful  \n",
       "870  ... is an arthritic endeavour at directing by ...  Successful  \n",
       "871  looking aristocratic , luminous yet careworn i...  Successful  \n",
       "\n",
       "[872 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df = pd.read_csv(osp.join(result_pth,'log.csv'))\n",
    "out_df = log_df[['original_text', 'perturbed_text', 'result_type']]\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a44e5fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>perturbed_text</th>\n",
       "      <th>original_score</th>\n",
       "      <th>perturbed_score</th>\n",
       "      <th>original_output</th>\n",
       "      <th>perturbed_output</th>\n",
       "      <th>ground_truth_output</th>\n",
       "      <th>num_queries</th>\n",
       "      <th>result_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it 's a charming and often affecting journey .</td>\n",
       "      <td>it 's a charming and normally affecting journe...</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unflinchingly bleak and desperate</td>\n",
       "      <td>unflinchingly grim and desperate</td>\n",
       "      <td>0.014329</td>\n",
       "      <td>0.154515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allows us to hope that nolan is poised to emba...</td>\n",
       "      <td>authorizes us to hopes that nolan is prepped t...</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.283926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the acting , costumes , music , cinematography...</td>\n",
       "      <td>the acting , costumes , music , cinematography...</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.622039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it 's slow -- very , very slow .</td>\n",
       "      <td>it 's slow -- very , very slower .</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>0.002501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>has all the depth of a wading pool .</td>\n",
       "      <td>has all the depths of a wading pool .</td>\n",
       "      <td>0.185487</td>\n",
       "      <td>0.851692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>a movie with a real anarchic flair .</td>\n",
       "      <td>a films with a true anarchic flair .</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>a subject like this should inspire reaction in...</td>\n",
       "      <td>a subject like this should inspiring reply in ...</td>\n",
       "      <td>0.136275</td>\n",
       "      <td>0.518427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>... is an arthritic attempt at directing by ca...</td>\n",
       "      <td>... is an arthritic endeavour at directing by ...</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>0.734410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>looking aristocratic , luminous yet careworn i...</td>\n",
       "      <td>looking aristocratic , luminous yet careworn i...</td>\n",
       "      <td>0.013619</td>\n",
       "      <td>0.820684</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>872 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         original_text  \\\n",
       "0      it 's a charming and often affecting journey .    \n",
       "1                   unflinchingly bleak and desperate    \n",
       "2    allows us to hope that nolan is poised to emba...   \n",
       "3    the acting , costumes , music , cinematography...   \n",
       "4                    it 's slow -- very , very slow .    \n",
       "..                                                 ...   \n",
       "867              has all the depth of a wading pool .    \n",
       "868              a movie with a real anarchic flair .    \n",
       "869  a subject like this should inspire reaction in...   \n",
       "870  ... is an arthritic attempt at directing by ca...   \n",
       "871  looking aristocratic , luminous yet careworn i...   \n",
       "\n",
       "                                        perturbed_text  original_score  \\\n",
       "0    it 's a charming and normally affecting journe...        0.000234   \n",
       "1                    unflinchingly grim and desperate         0.014329   \n",
       "2    authorizes us to hopes that nolan is prepped t...        0.000426   \n",
       "3    the acting , costumes , music , cinematography...        0.003972   \n",
       "4                  it 's slow -- very , very slower .         0.002048   \n",
       "..                                                 ...             ...   \n",
       "867             has all the depths of a wading pool .         0.185487   \n",
       "868              a films with a true anarchic flair .         0.000322   \n",
       "869  a subject like this should inspiring reply in ...        0.136275   \n",
       "870  ... is an arthritic endeavour at directing by ...        0.003134   \n",
       "871  looking aristocratic , luminous yet careworn i...        0.013619   \n",
       "\n",
       "     perturbed_score  original_output  perturbed_output  ground_truth_output  \\\n",
       "0           0.000557              1.0               1.0                  1.0   \n",
       "1           0.154515              0.0               0.0                  0.0   \n",
       "2           0.283926              1.0               1.0                  1.0   \n",
       "3           0.622039              1.0               0.0                  1.0   \n",
       "4           0.002501              0.0               0.0                  0.0   \n",
       "..               ...              ...               ...                  ...   \n",
       "867         0.851692              0.0               1.0                  0.0   \n",
       "868         0.000818              1.0               1.0                  1.0   \n",
       "869         0.518427              0.0               1.0                  0.0   \n",
       "870         0.734410              0.0               1.0                  0.0   \n",
       "871         0.820684              1.0               0.0                  1.0   \n",
       "\n",
       "     num_queries result_type  \n",
       "0           14.0      Failed  \n",
       "1            5.0      Failed  \n",
       "2           32.0      Failed  \n",
       "3            8.0  Successful  \n",
       "4            4.0      Failed  \n",
       "..           ...         ...  \n",
       "867          2.0  Successful  \n",
       "868          5.0      Failed  \n",
       "869         13.0  Successful  \n",
       "870         11.0  Successful  \n",
       "871          9.0  Successful  \n",
       "\n",
       "[872 rows x 9 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7446d576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transformation</th>\n",
       "      <th>prev_text</th>\n",
       "      <th>after_text</th>\n",
       "      <th>prev_target</th>\n",
       "      <th>after_target</th>\n",
       "      <th>from_modified_indices</th>\n",
       "      <th>to_modified_indices</th>\n",
       "      <th>changes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transformation_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'class': 'WordSwapEmbedding', 'max_candidates...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{3}</td>\n",
       "      <td>{3}</td>\n",
       "      <td>['replace: [3,4]-[3,4]']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'class': 'WordSwapEmbedding', 'max_candidates...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{3}</td>\n",
       "      <td>{3}</td>\n",
       "      <td>['replace: [3,4]-[3,4]']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'class': 'WordSwapEmbedding', 'max_candidates...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{3}</td>\n",
       "      <td>{3}</td>\n",
       "      <td>['replace: [3,4]-[3,4]']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'class': 'WordSwapEmbedding', 'max_candidates...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{3}</td>\n",
       "      <td>{3}</td>\n",
       "      <td>['replace: [3,4]-[3,4]']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'class': 'WordSwapEmbedding', 'max_candidates...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{3}</td>\n",
       "      <td>{3}</td>\n",
       "      <td>['replace: [3,4]-[3,4]']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>{'class': 'WordSwapEmbedding', 'max_candidates...</td>\n",
       "      <td>1982</td>\n",
       "      <td>2095</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{15}</td>\n",
       "      <td>{15}</td>\n",
       "      <td>['replace: [15,16]-[15,16]']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>{'class': 'WordSwapEmbedding', 'max_candidates...</td>\n",
       "      <td>1982</td>\n",
       "      <td>2096</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{15}</td>\n",
       "      <td>{15}</td>\n",
       "      <td>['replace: [15,16]-[15,16]']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>{'class': 'WordSwapEmbedding', 'max_candidates...</td>\n",
       "      <td>1982</td>\n",
       "      <td>2097</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{15}</td>\n",
       "      <td>{15}</td>\n",
       "      <td>['replace: [15,16]-[15,16]']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>{'class': 'WordSwapEmbedding', 'max_candidates...</td>\n",
       "      <td>1982</td>\n",
       "      <td>2098</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{15}</td>\n",
       "      <td>{15}</td>\n",
       "      <td>['replace: [15,16]-[15,16]']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>{'class': 'WordSwapEmbedding', 'max_candidates...</td>\n",
       "      <td>1982</td>\n",
       "      <td>2099</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{15}</td>\n",
       "      <td>{15}</td>\n",
       "      <td>['replace: [15,16]-[15,16]']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2080 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      transformation  \\\n",
       "transformation_id                                                      \n",
       "0                  {'class': 'WordSwapEmbedding', 'max_candidates...   \n",
       "1                  {'class': 'WordSwapEmbedding', 'max_candidates...   \n",
       "2                  {'class': 'WordSwapEmbedding', 'max_candidates...   \n",
       "3                  {'class': 'WordSwapEmbedding', 'max_candidates...   \n",
       "4                  {'class': 'WordSwapEmbedding', 'max_candidates...   \n",
       "...                                                              ...   \n",
       "2075               {'class': 'WordSwapEmbedding', 'max_candidates...   \n",
       "2076               {'class': 'WordSwapEmbedding', 'max_candidates...   \n",
       "2077               {'class': 'WordSwapEmbedding', 'max_candidates...   \n",
       "2078               {'class': 'WordSwapEmbedding', 'max_candidates...   \n",
       "2079               {'class': 'WordSwapEmbedding', 'max_candidates...   \n",
       "\n",
       "                   prev_text  after_text  prev_target  after_target  \\\n",
       "transformation_id                                                     \n",
       "0                          0           1           -1            -1   \n",
       "1                          2           3           -1            -1   \n",
       "2                          2           4           -1            -1   \n",
       "3                          2           5           -1            -1   \n",
       "4                          2           6           -1            -1   \n",
       "...                      ...         ...          ...           ...   \n",
       "2075                    1982        2095           -1            -1   \n",
       "2076                    1982        2096           -1            -1   \n",
       "2077                    1982        2097           -1            -1   \n",
       "2078                    1982        2098           -1            -1   \n",
       "2079                    1982        2099           -1            -1   \n",
       "\n",
       "                  from_modified_indices to_modified_indices  \\\n",
       "transformation_id                                             \n",
       "0                                   {3}                 {3}   \n",
       "1                                   {3}                 {3}   \n",
       "2                                   {3}                 {3}   \n",
       "3                                   {3}                 {3}   \n",
       "4                                   {3}                 {3}   \n",
       "...                                 ...                 ...   \n",
       "2075                               {15}                {15}   \n",
       "2076                               {15}                {15}   \n",
       "2077                               {15}                {15}   \n",
       "2078                               {15}                {15}   \n",
       "2079                               {15}                {15}   \n",
       "\n",
       "                                        changes  \n",
       "transformation_id                                \n",
       "0                      ['replace: [3,4]-[3,4]']  \n",
       "1                      ['replace: [3,4]-[3,4]']  \n",
       "2                      ['replace: [3,4]-[3,4]']  \n",
       "3                      ['replace: [3,4]-[3,4]']  \n",
       "4                      ['replace: [3,4]-[3,4]']  \n",
       "...                                         ...  \n",
       "2075               ['replace: [15,16]-[15,16]']  \n",
       "2076               ['replace: [15,16]-[15,16]']  \n",
       "2077               ['replace: [15,16]-[15,16]']  \n",
       "2078               ['replace: [15,16]-[15,16]']  \n",
       "2079               ['replace: [15,16]-[15,16]']  \n",
       "\n",
       "[2080 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformation_log = pd.read_csv('../results/transformation.csv', index_col=0, names = [\"transformation_id\",\"transformation\",\n",
    "            \"prev_text\", \"after_text\", \"prev_target\", \"after_target\",\"from_modified_indices\", \"to_modified_indices\", \"changes\"])\n",
    "transformation_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b786302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>transformation</th>\n",
       "      <th>prev_target</th>\n",
       "      <th>after_target</th>\n",
       "      <th>from_modified_indices</th>\n",
       "      <th>to_modified_indices</th>\n",
       "      <th>changes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev_text</th>\n",
       "      <th>after_text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>{'class': 'WordSwapEmbedding', 'max_candidates...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{3}</td>\n",
       "      <td>{3}</td>\n",
       "      <td>['replace: [3,4]-[3,4]']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th>3</th>\n",
       "      <td>{'class': 'WordSwapEmbedding', 'max_candidates...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{3}</td>\n",
       "      <td>{3}</td>\n",
       "      <td>['replace: [3,4]-[3,4]']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'class': 'WordSwapEmbedding', 'max_candidates...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{3}</td>\n",
       "      <td>{3}</td>\n",
       "      <td>['replace: [3,4]-[3,4]']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'class': 'WordSwapEmbedding', 'max_candidates...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{3}</td>\n",
       "      <td>{3}</td>\n",
       "      <td>['replace: [3,4]-[3,4]']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'class': 'WordSwapEmbedding', 'max_candidates...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{3}</td>\n",
       "      <td>{3}</td>\n",
       "      <td>['replace: [3,4]-[3,4]']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1982</th>\n",
       "      <th>2095</th>\n",
       "      <td>{'class': 'WordSwapEmbedding', 'max_candidates...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{15}</td>\n",
       "      <td>{15}</td>\n",
       "      <td>['replace: [15,16]-[15,16]']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>{'class': 'WordSwapEmbedding', 'max_candidates...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{15}</td>\n",
       "      <td>{15}</td>\n",
       "      <td>['replace: [15,16]-[15,16]']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>{'class': 'WordSwapEmbedding', 'max_candidates...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{15}</td>\n",
       "      <td>{15}</td>\n",
       "      <td>['replace: [15,16]-[15,16]']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>{'class': 'WordSwapEmbedding', 'max_candidates...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{15}</td>\n",
       "      <td>{15}</td>\n",
       "      <td>['replace: [15,16]-[15,16]']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>{'class': 'WordSwapEmbedding', 'max_candidates...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>{15}</td>\n",
       "      <td>{15}</td>\n",
       "      <td>['replace: [15,16]-[15,16]']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2080 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         transformation  \\\n",
       "prev_text after_text                                                      \n",
       "0         1           {'class': 'WordSwapEmbedding', 'max_candidates...   \n",
       "2         3           {'class': 'WordSwapEmbedding', 'max_candidates...   \n",
       "          4           {'class': 'WordSwapEmbedding', 'max_candidates...   \n",
       "          5           {'class': 'WordSwapEmbedding', 'max_candidates...   \n",
       "          6           {'class': 'WordSwapEmbedding', 'max_candidates...   \n",
       "...                                                                 ...   \n",
       "1982      2095        {'class': 'WordSwapEmbedding', 'max_candidates...   \n",
       "          2096        {'class': 'WordSwapEmbedding', 'max_candidates...   \n",
       "          2097        {'class': 'WordSwapEmbedding', 'max_candidates...   \n",
       "          2098        {'class': 'WordSwapEmbedding', 'max_candidates...   \n",
       "          2099        {'class': 'WordSwapEmbedding', 'max_candidates...   \n",
       "\n",
       "                      prev_target  after_target from_modified_indices  \\\n",
       "prev_text after_text                                                    \n",
       "0         1                    -1            -1                   {3}   \n",
       "2         3                    -1            -1                   {3}   \n",
       "          4                    -1            -1                   {3}   \n",
       "          5                    -1            -1                   {3}   \n",
       "          6                    -1            -1                   {3}   \n",
       "...                           ...           ...                   ...   \n",
       "1982      2095                 -1            -1                  {15}   \n",
       "          2096                 -1            -1                  {15}   \n",
       "          2097                 -1            -1                  {15}   \n",
       "          2098                 -1            -1                  {15}   \n",
       "          2099                 -1            -1                  {15}   \n",
       "\n",
       "                     to_modified_indices                       changes  \n",
       "prev_text after_text                                                    \n",
       "0         1                          {3}      ['replace: [3,4]-[3,4]']  \n",
       "2         3                          {3}      ['replace: [3,4]-[3,4]']  \n",
       "          4                          {3}      ['replace: [3,4]-[3,4]']  \n",
       "          5                          {3}      ['replace: [3,4]-[3,4]']  \n",
       "          6                          {3}      ['replace: [3,4]-[3,4]']  \n",
       "...                                  ...                           ...  \n",
       "1982      2095                      {15}  ['replace: [15,16]-[15,16]']  \n",
       "          2096                      {15}  ['replace: [15,16]-[15,16]']  \n",
       "          2097                      {15}  ['replace: [15,16]-[15,16]']  \n",
       "          2098                      {15}  ['replace: [15,16]-[15,16]']  \n",
       "          2099                      {15}  ['replace: [15,16]-[15,16]']  \n",
       "\n",
       "[2080 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_to_transformation = transformation_log.set_index(['prev_text', 'after_text'])\n",
    "edge_to_transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26f5bd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df = transformation_log[['prev_text','after_text']]\n",
    "forward_edges_df = edges_df.set_index('prev_text')\n",
    "backward_edges_df = edges_df.set_index('after_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0ce4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_text = pd.read_csv('../results/text.csv', index_col=\"text_id\", names = [\"text_id\", \"text\"])\n",
    "text_to_id = pd.read_csv('../results/text.csv', index_col=\"text\", names = [\"text_id\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75231e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<breakdown.n.03: PosScore=0.0 NegScore=0.25>\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "print(swn.senti_synset('breakdown.n.03'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1af2ad37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f951afdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4783"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eee37c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SentiSynset('decelerate.v.01'),\n",
       " SentiSynset('slow.v.02'),\n",
       " SentiSynset('slow.v.03'),\n",
       " SentiSynset('slow.a.01'),\n",
       " SentiSynset('slow.a.02'),\n",
       " SentiSynset('dense.s.04'),\n",
       " SentiSynset('slow.a.04'),\n",
       " SentiSynset('boring.s.01'),\n",
       " SentiSynset('dull.s.08'),\n",
       " SentiSynset('slowly.r.01'),\n",
       " SentiSynset('behind.r.03')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(swn.senti_synsets('slow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "275ebe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "happy = swn.senti_synsets('happy', 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c55591eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SentiSynset('happy.a.01'),\n",
       " SentiSynset('felicitous.s.02'),\n",
       " SentiSynset('glad.s.02'),\n",
       " SentiSynset('happy.s.04')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(happy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "739ef9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy = swn.senti_synsets('happy', 'a')\n",
    "happy0 = list(happy)[1]\n",
    "happy0.pos_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69e4f1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy0.neg_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69dd878d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy0.obj_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300f88cf",
   "metadata": {},
   "source": [
    "## Transformation History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2173446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 12:47:23.458798: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from lineage import InferQuery\n",
    "from collections import defaultdict\n",
    "from textattack.shared.utils import words_from_text\n",
    "queryAPI = InferQuery(dir_pth='./results_a2t_sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9524b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2504,\n",
       "  \"nicks , seemingly uncertain what 's going to make people laugh , runs the gamut from stale parody to raunchy sex gags to formula romantic comedy . \",\n",
       "  0.0),\n",
       " (\"{'class': 'WordSwapEmbedding', 'max_candidates': 20, 'embedding': WordEmbedding}\",\n",
       "  '{21}',\n",
       "  '{21}'),\n",
       " [('replace', (21, 22), (21, 22))],\n",
       " (2505,\n",
       "  \"nicks , seemingly uncertain what 's going to make people laugh , runs the gamut from stale parody to raunchy sex gags to formulas romantic comedy . \",\n",
       "  0.0),\n",
       " (\"{'class': 'WordSwapEmbedding', 'max_candidates': 20, 'embedding': WordEmbedding}\",\n",
       "  '{14}',\n",
       "  '{14}'),\n",
       " [('replace', (14, 15), (14, 15))],\n",
       " (2529,\n",
       "  \"nicks , seemingly uncertain what 's going to make people laugh , runs the gamut from archaic parody to raunchy sex gags to formulas romantic comedy . \",\n",
       "  0.0),\n",
       " (\"{'class': 'WordSwapEmbedding', 'max_candidates': 20, 'embedding': WordEmbedding}\",\n",
       "  '{12}',\n",
       "  '{12}'),\n",
       " [('replace', (12, 13), (12, 13))],\n",
       " (2545,\n",
       "  \"nicks , seemingly uncertain what 's going to make people laugh , runs the spectrum from archaic parody to raunchy sex gags to formulas romantic comedy . \",\n",
       "  1.0)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_trace = queryAPI.get_trace_of_output_idx(25)\n",
    "api_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b12a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_traces = queryAPI.get_traces_of_all_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "291ef7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, \"it 's a charming and often affecting journey . \", 1.0),\n",
       " (\"{'class': 'WordSwapEmbedding', 'max_candidates': 20, 'embedding': WordEmbedding}\",\n",
       "  '{5}',\n",
       "  '{5}'),\n",
       " [('replace', (5, 6), (5, 6))],\n",
       " (28, \"it 's a charming and normally affecting journey . \", 1.0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_traces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3cdc29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "806"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a25e9b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package opinion_lexicon to stopwords...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('opinion_lexicon','stopwords')\n",
    "\n",
    "pos_list=set(opinion_lexicon.positive())\n",
    "neg_list=set(opinion_lexicon.negative())\n",
    "stop_words = set(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9683aa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sentiment_category(word):\n",
    "    if  word in stop_words:\n",
    "        return 'exclude'\n",
    "    elif word in pos_list:\n",
    "        return 'pos'\n",
    "    elif word in neg_list:\n",
    "        return 'neg'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2b65b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edits = {}\n",
    "for record in all_traces:\n",
    "    for i,step in enumerate(record):\n",
    "        if isinstance(step, list):\n",
    "            for edit in step:\n",
    "                op = edit[0]\n",
    "                from_span = edit[1]\n",
    "                to_span = edit[2]\n",
    "                from_text = tuple(words_from_text(record[i-2][1])[from_span[0]:from_span[1]])\n",
    "                to_text = tuple(words_from_text(record[i+1][1])[to_span[0]:to_span[1]])\n",
    "                \n",
    "                from_label = record[i-2][2]\n",
    "                to_label = record[i+1][2]\n",
    "                \n",
    "                # to category\n",
    "                from_cat = to_sentiment_category(from_text[0])\n",
    "                to_cat = to_sentiment_category(to_text[0])\n",
    "                \n",
    "                result_type = record[i+1][2]\n",
    "                if op not in all_edits:\n",
    "                    all_edits[op] = defaultdict(dict)\n",
    "                if to_cat not in all_edits[op][from_cat]:\n",
    "                    all_edits[op][from_cat][to_cat]={}\n",
    "                if (from_label, to_label) not in all_edits[op][from_cat][to_cat]:\n",
    "                    all_edits[op][from_cat][to_cat][(from_label, to_label)] = []\n",
    "                    \n",
    "                all_edits[op][from_cat][to_cat][(from_label, to_label)].append((from_text, to_text)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4136175",
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_freqs = defaultdict(list)\n",
    "for op in all_edits.keys():\n",
    "    for from_cat in all_edits[op].keys():\n",
    "        for to_cat in all_edits[op][from_cat].keys():\n",
    "            for label_pair in all_edits[op][from_cat][to_cat].keys():\n",
    "                edit_freqs[label_pair].append((len(all_edits[op][from_cat][to_cat][label_pair]), op, from_cat, to_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "887c6c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 1.0)\n",
      "\t(659, 'replace', 'neutral', 'neutral')\n",
      "\t(134, 'replace', 'pos', 'neutral')\n",
      "\t(106, 'replace', 'pos', 'pos')\n",
      "\t(55, 'replace', 'neg', 'neg')\n",
      "\t(42, 'replace', 'neg', 'neutral')\n",
      "\t(30, 'replace', 'neutral', 'neg')\n",
      "\t(29, 'replace', 'neutral', 'pos')\n",
      "\t(18, 'replace', 'pos', 'neg')\n",
      "\t(7, 'replace', 'neutral', 'exclude')\n",
      "\t(2, 'replace', 'neg', 'pos')\n",
      "(1.0, 0.0)\n",
      "\t(52, 'replace', 'neutral', 'neutral')\n",
      "\t(16, 'replace', 'neg', 'neg')\n",
      "\t(10, 'replace', 'pos', 'pos')\n",
      "\t(8, 'replace', 'pos', 'neutral')\n",
      "\t(7, 'replace', 'neutral', 'neg')\n",
      "\t(3, 'replace', 'neg', 'neutral')\n",
      "\t(2, 'replace', 'neutral', 'exclude')\n",
      "\t(1, 'replace', 'pos', 'neg')\n",
      "(0.0, 0.0)\n",
      "\t(586, 'replace', 'neutral', 'neutral')\n",
      "\t(124, 'replace', 'neg', 'neg')\n",
      "\t(60, 'replace', 'neg', 'neutral')\n",
      "\t(50, 'replace', 'pos', 'pos')\n",
      "\t(36, 'replace', 'neutral', 'pos')\n",
      "\t(32, 'replace', 'pos', 'neutral')\n",
      "\t(18, 'replace', 'neutral', 'neg')\n",
      "\t(13, 'replace', 'neg', 'pos')\n",
      "\t(9, 'replace', 'neutral', 'exclude')\n",
      "\t(1, 'replace', 'pos', 'neg')\n",
      "(0.0, 1.0)\n",
      "\t(55, 'replace', 'neutral', 'neutral')\n",
      "\t(7, 'replace', 'neutral', 'pos')\n",
      "\t(7, 'replace', 'neg', 'neutral')\n",
      "\t(7, 'replace', 'neg', 'neg')\n",
      "\t(6, 'replace', 'pos', 'pos')\n",
      "\t(4, 'replace', 'pos', 'neutral')\n",
      "\t(2, 'replace', 'neutral', 'neg')\n",
      "\t(2, 'replace', 'neg', 'pos')\n",
      "\t(1, 'replace', 'pos', 'neg')\n",
      "\t(1, 'replace', 'neutral', 'exclude')\n"
     ]
    }
   ],
   "source": [
    "for label_pair in edit_freqs.keys():\n",
    "    print(label_pair)\n",
    "    edit_freqs[label_pair] = sorted(edit_freqs[label_pair], reverse=True)\n",
    "    for edit in edit_freqs[label_pair]:\n",
    "        print(f\"\\t{edit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e774420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 1.0)\n",
      "\t('replace', 'neg', 'neg'), 5.08%\n",
      "\t('replace', 'neg', 'neutral'), 3.88%\n",
      "\t('replace', 'neg', 'pos'), 0.18%\n",
      "\t('replace', 'neutral', 'exclude'), 0.65%\n",
      "\t('replace', 'neutral', 'neg'), 2.77%\n",
      "\t('replace', 'neutral', 'neutral'), 60.91%\n",
      "\t('replace', 'neutral', 'pos'), 2.68%\n",
      "\t('replace', 'pos', 'neg'), 1.66%\n",
      "\t('replace', 'pos', 'neutral'), 12.38%\n",
      "\t('replace', 'pos', 'pos'), 9.80%\n",
      "(1.0, 0.0)\n",
      "\t('replace', 'neg', 'neg'), 16.16%\n",
      "\t('replace', 'neg', 'neutral'), 3.03%\n",
      "\t('replace', 'neutral', 'exclude'), 2.02%\n",
      "\t('replace', 'neutral', 'neg'), 7.07%\n",
      "\t('replace', 'neutral', 'neutral'), 52.53%\n",
      "\t('replace', 'pos', 'neg'), 1.01%\n",
      "\t('replace', 'pos', 'neutral'), 8.08%\n",
      "\t('replace', 'pos', 'pos'), 10.10%\n",
      "(0.0, 0.0)\n",
      "\t('replace', 'neg', 'neg'), 13.35%\n",
      "\t('replace', 'neg', 'neutral'), 6.46%\n",
      "\t('replace', 'neg', 'pos'), 1.40%\n",
      "\t('replace', 'neutral', 'exclude'), 0.97%\n",
      "\t('replace', 'neutral', 'neg'), 1.94%\n",
      "\t('replace', 'neutral', 'neutral'), 63.08%\n",
      "\t('replace', 'neutral', 'pos'), 3.88%\n",
      "\t('replace', 'pos', 'neg'), 0.11%\n",
      "\t('replace', 'pos', 'neutral'), 3.44%\n",
      "\t('replace', 'pos', 'pos'), 5.38%\n",
      "(0.0, 1.0)\n",
      "\t('replace', 'neg', 'neg'), 7.61%\n",
      "\t('replace', 'neg', 'neutral'), 7.61%\n",
      "\t('replace', 'neg', 'pos'), 2.17%\n",
      "\t('replace', 'neutral', 'exclude'), 1.09%\n",
      "\t('replace', 'neutral', 'neg'), 2.17%\n",
      "\t('replace', 'neutral', 'neutral'), 59.78%\n",
      "\t('replace', 'neutral', 'pos'), 7.61%\n",
      "\t('replace', 'pos', 'neg'), 1.09%\n",
      "\t('replace', 'pos', 'neutral'), 4.35%\n",
      "\t('replace', 'pos', 'pos'), 6.52%\n"
     ]
    }
   ],
   "source": [
    "label_percentage = {}\n",
    "for label_pair in edit_freqs.keys():\n",
    "    freq_sum = sum([tup[0] for tup in edit_freqs[label_pair]])\n",
    "    edits_dict = {}\n",
    "    for edit in edit_freqs[label_pair]:\n",
    "        edits_dict[edit[1:]] = edit[0]/freq_sum * 100\n",
    "    label_percentage[label_pair] = edits_dict\n",
    "        \n",
    "for label_pair in label_percentage.keys():\n",
    "    print(label_pair)\n",
    "    for edit in sorted(label_percentage[label_pair].keys()):\n",
    "        print(f\"\\t{edit}, {label_percentage[label_pair][edit]:.2f}%\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "16094eee",
   "metadata": {},
   "source": [
    "for result in results:\n",
    "    original_text = result.original_result.attacked_text\n",
    "    perturbed_text = result.perturbed_result.attacked_text\n",
    "    \n",
    "    trans_trace = queryAPI.get_transfromation_history(perturbed_text)\n",
    "    \n",
    "    for trans in trans_trace:\n",
    "        print(trans)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpml",
   "language": "python",
   "name": "dpml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
