{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e04c455",
   "metadata": {},
   "source": [
    "# AMR Analysis\n",
    "\n",
    "- References:\n",
    "  - https://github.com/Sean-Blank/AMRcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da2b8d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cf5f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from datasets import load_dataset, Dataset\n",
    "from sibyl import *\n",
    "import random\n",
    "import pandas as pd\n",
    "import amrlib\n",
    "import penman\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "torch.use_deterministic_algorithms(False)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5521f9c0",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ac802fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (C:/Users/Fabrice/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"glue\", \"sst2\", split=\"train\")\n",
    "dataset = dataset.rename_column(\"sentence\", \"text\")\n",
    "original_text, original_labels = dataset['text'], dataset['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2fc382",
   "metadata": {},
   "source": [
    "### Boolean Featurizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caba3a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "stog = amrlib.load_stog_model(device=0, max_sent_len=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c855c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2amr(texts):\n",
    "    # if not isinstance(texts, list): texts = [texts]\n",
    "    gs = stog.parse_sents(texts, add_metadata=False)\n",
    "    gs = [LeGraph(g) for g in gs]\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7b1fbbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeGraph:\n",
    "    def __init__(self, graph):\n",
    "        self.graph = penman.decode(graph) if not isinstance(graph, penman.graph.Graph) else graph\n",
    "        self.amr_text = penman.encode(self.graph)\n",
    "\n",
    "    def contains_concept(self, concepts):\n",
    "        \"\"\"\n",
    "        Concepts are nodes / instances in the AMR graph.\n",
    "        \"\"\"\n",
    "        if not isinstance(concepts, list): concepts = [concepts]\n",
    "        graph_concepts = [t.target for t in self.graph.instances()]\n",
    "        return any(c for c in graph_concepts if c in concepts)\n",
    "\n",
    "    def contains_role(self, roles):\n",
    "        \"\"\"\n",
    "        Roles are edges in the AMR graph.\n",
    "        \"\"\"\n",
    "        if not isinstance(roles, list): roles = [roles]\n",
    "        print(roles)\n",
    "        graph_roles = [e.role for e in self.graph.edges()]\n",
    "        print(graph_roles)\n",
    "        print(self.graph.edges())\n",
    "        return any(r for r in graph_roles if r in roles)\n",
    "\n",
    "    def contains_attribute(self, attributes):\n",
    "        \"\"\"\n",
    "        Attributes are properties of concept nodes, i.e. relationships to \n",
    "        constant values.\n",
    "        \"\"\"\n",
    "        if not isinstance(attributes, list): attributes = [attributes]\n",
    "        graph_attrs = [a.target for a in self.graph.attributes()]\n",
    "        return any(a for a in graph_attrs if a in attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1433babe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_duplicates(X):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    for x in X:\n",
    "        if (x in seen or seen_add(x)):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a697f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributes =============================================================\n",
    "\n",
    "def contains_imperative(g): return g.contains_attribute(\"imperative\")\n",
    "def contains_exlamation(g): return g.contains_attribute(\"expressive\")\n",
    "def contains_negation(g):   return g.contains_attribute(\"-\")\n",
    "\n",
    "# concepts ===============================================================\n",
    "\n",
    "def contains_conjunctions(g):         return g.contains_concept([\"and\", \"or\", \"contrast-01\", \"either\", \"neither\"])\n",
    "def contains_interrogative_clause(g): return g.contains_concept(\"truth-value\")\n",
    "def contains_question(g):             return g.contains_concept([\"amr-unknown\", \"amr-choice\"])\n",
    "\n",
    "# roles ==================================================================\n",
    "\n",
    "def contains_coreferences(g): return any(r for r in g.amr_text.split() if r in ['i', 'you', 'he', 'she', 'it', 'we', 'they'])\n",
    "def contains_number(g):       return any(a for a in g.graph.attributes() if a.target.isnumeric())\n",
    "\n",
    "def contains_accompanier(g):  return g.contains_role(':accompanier')\n",
    "def contains_age(g):          return g.contains_role(':age')\n",
    "def contains_beneficiary(g):  return g.contains_role(':beneficiary')\n",
    "def contains_concession(g):   return g.contains_role(':concession')\n",
    "def contains_condition(g):    return g.contains_role(':condition')\n",
    "def contains_consist_of(g):   return any(r for r in g.amr_text.split() if r in [':consist-of'])\n",
    "def contains_degree(g):       return g.contains_role(':degree')\n",
    "def contains_destination(g):  return g.contains_role(':destination')\n",
    "def contains_direction(g):    return g.contains_role(':direction')\n",
    "def contains_domain(g):       return g.contains_role(':domain')\n",
    "def contains_duration(g):     return g.contains_role(':duration')\n",
    "def contains_example(g):      return g.contains_role(':example')\n",
    "def contains_extent(g):       return g.contains_role(':extent')\n",
    "def contains_frequency(g):    return g.contains_role(':frequency')\n",
    "def contains_instrument(g):   return g.contains_role(':instrument')\n",
    "# def contains_li(g):           return g.contains_role(':li')\n",
    "def contains_location(g):     return g.contains_role(':location')\n",
    "def contains_manner(g):       return g.contains_role(':manner')\n",
    "def contains_medium(g):       return g.contains_role(':medium')\n",
    "def contains_mod(g):          return g.contains_role(':mod')\n",
    "def contains_mode(g):         return any(a for a in g.graph.attributes() if \":mode\" in a.role)\n",
    "def contains_name(g):         return g.contains_role(':name')\n",
    "def contains_ord(g):          return g.contains_role(':ord')\n",
    "def contains_part(g):         return g.contains_role(':part')\n",
    "def contains_path(g):         return g.contains_role(':path')\n",
    "def contains_polarity(g):     return g.contains_role(':polarity')\n",
    "def contains_polite(g):       return any(r for r in g.amr_text.split() if r in [':polite'])\n",
    "def contains_poss(g):         return g.contains_role(':poss')\n",
    "def contains_purpose(g):      return g.contains_role(':purpose')\n",
    "def contains_quant(g):        return g.contains_role(':quant')\n",
    "def contains_range(g):        return g.contains_role(':range')\n",
    "def contains_scale(g):        return g.contains_role(':scale')\n",
    "def contains_source(g):       return g.contains_role(':source')\n",
    "def contains_subevent(g):     return g.contains_role(':subevent')\n",
    "def contains_time(g):         return g.contains_role(':time')\n",
    "def contains_topic(g):        return g.contains_role(':topic')\n",
    "def contains_unit(g):         return g.contains_role(':unit')\n",
    "# def contains_value(g):        return g.contains_role(':value')\n",
    "def contains_wiki(g):         return g.contains_role(':wiki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e97b2c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "def pickle_list(a_list, a_path):\n",
    "    with open(a_path, 'wb') as fp:\n",
    "        pickle.dump(a_list, fp)\n",
    "\n",
    "def unpickle_list(a_path):\n",
    "    with open(a_path, 'rb') as fp:\n",
    "        n_list = pickle.load(fp)\n",
    "        return n_list\n",
    "\n",
    "# def write_list(a_list, a_path):\n",
    "#     with open(a_path, 'w') as fp:\n",
    "#         fp.write('\\n'.join(a_list))\n",
    "\n",
    "# def read_list(a_path):\n",
    "#     with open(a_path, 'r') as fp:\n",
    "#         n_list = fp.read().split(\"\\n\")\n",
    "#         return n_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b9953a",
   "metadata": {},
   "source": [
    "### Convert Text to AMRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd1f6889",
   "metadata": {},
   "outputs": [],
   "source": [
    "penman_path = \"penmans.pkl\"\n",
    "batch_size = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb5a0c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading precomputed amrs...\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(penman_path):\n",
    "    print(\"computing amrs...\")\n",
    "    amrs = []\n",
    "    for texts in tqdm(chunker(original_text, batch_size), total=len(original_text)/batch_size):\n",
    "        amrs.extend(text2amr(texts))\n",
    "    pickle_list(amrs, penman_path)\n",
    "else:\n",
    "    print(\"loading precomputed amrs...\")\n",
    "    amrs = unpickle_list(penman_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053e8eda",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e94b8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(task=\"sentiment-analysis\", device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3341e6e2",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72238516",
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = [Concept2Sentence, ConceptMix, Emojify]\n",
    "ts = [t(task_name=\"sentiment\", return_metadata=True) for t in TRANSFORMATIONS if t not in blacklist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edffadf9",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c73e3bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sibyl import acc_at_k\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "279762ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_probs(results):\n",
    "    return np.array([[1-r['score'], r['score']] if r['label'] == \"POSITIVE\" else [r['score'], 1-r['score']] for r in results])\n",
    "\n",
    "def compute_accuracy(predictions, labels):\n",
    "    if len(labels.shape) > 1:\n",
    "        acc = acc_at_k(labels, predictions, k=2)       \n",
    "    else:\n",
    "        acc = accuracy_score(labels, np.argmax(predictions, -1))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4cffc857",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMRBooleanFeature:\n",
    "    def __init__(self, dataset, amrs, min_samples=5):\n",
    "        self.dataset = dataset\n",
    "        self.amrs = amrs     \n",
    "        self.min_samples = min_samples\n",
    "    \n",
    "    def extract_data_containing_feature(self, featurizer, max_size=1000):\n",
    "        \n",
    "        self.featurizer = featurizer \n",
    "        \n",
    "        # extract T and F evaluation sets\n",
    "        ts, fs = [], []\n",
    "        for g, s, l in zip(self.amrs, self.dataset['text'], self.dataset['label']):\n",
    "            if self.featurizer(g):\n",
    "                ts.append((s, l))\n",
    "                if len(ts) >= max_size:\n",
    "                    break\n",
    "            else:\n",
    "                fs.append((s,l))\n",
    "        \n",
    "        len_ts = len(ts)\n",
    "        len_fs = len(fs)\n",
    "        \n",
    "        if len_ts < self.min_samples:\n",
    "            print(f\"Only {len_ts} inputs contain the feature, skipping for insufficient data...\")\n",
    "            self.t_dataset = []\n",
    "            self.f_dataset = []\n",
    "            return\n",
    "        if len_fs < len_ts:\n",
    "            ts = ts[:len_fs]\n",
    "\n",
    "        t_texts, t_labels = zip(*ts)\n",
    "        f_texts, f_labels = zip(*random.sample(fs, len(t_texts)))\n",
    "\n",
    "        t_texts, t_labels = list(t_texts), one_hot_encode(t_labels, 2)\n",
    "        f_texts, f_labels = list(f_texts), one_hot_encode(f_labels, 2)\n",
    "\n",
    "        self.t_dataset = Dataset.from_list(\n",
    "            [{'text': t, 'label': l} for t, l in zip(t_texts, t_labels)])\n",
    "        self.f_dataset = Dataset.from_list(\n",
    "            [{'text': t, 'label': l} for t, l in zip(f_texts, f_labels)])\n",
    "            \n",
    "    def generate_transformed_datasets(self, transform):\n",
    "        \n",
    "        self.transform = transform\n",
    "         \n",
    "        # apply transformation to each set of texts containing the target feature\n",
    "        transformed_t_text, transformed_t_labels = transform.transform_batch(\n",
    "            batch=(self.t_dataset['text'], self.t_dataset['label']))\n",
    "        transformed_f_text, transformed_f_labels = transform.transform_batch(\n",
    "            batch=(self.f_dataset['text'], self.f_dataset['label']))\n",
    "        transformed_t_labels = np.stack([np.array(a).squeeze() for a in transformed_t_labels])\n",
    "        transformed_f_labels = np.stack([np.array(a).squeeze() for a in transformed_f_labels])\n",
    "        \n",
    "        self.tran_t_dataset = Dataset.from_list(\n",
    "            [{'text': t, 'label': l} for t, l in zip(transformed_t_text, transformed_t_labels)])\n",
    "        self.tran_f_dataset = Dataset.from_list(\n",
    "            [{'text': t, 'label': l} for t, l in zip(transformed_f_text, transformed_f_labels)]) \n",
    "        \n",
    "        self.t_changed = sum([t1 != t2 for t1, t2 in zip(self.t_dataset, self.tran_t_dataset)]) / len(self.t_dataset['text'])\n",
    "        self.f_changed = sum([t1 != t2 for t1, t2 in zip(self.f_dataset, self.tran_f_dataset)]) / len(self.f_dataset['text'])\n",
    "    \n",
    "    def evaluate_original(self, pipe):\n",
    "        \n",
    "        # pass data through the model\n",
    "        self.orig_t_preds = extract_probs(pipe(KeyDataset(self.t_dataset, \"text\")))\n",
    "        self.orig_f_preds = extract_probs(pipe(KeyDataset(self.f_dataset, \"text\")))\n",
    "        \n",
    "        # compute accuracy\n",
    "        self.orig_t_acc = compute_accuracy(\n",
    "            self.orig_t_preds, np.argmax(self.t_dataset['label'], -1))\n",
    "        self.orig_f_acc = compute_accuracy(\n",
    "            self.orig_f_preds, np.argmax(self.f_dataset['label'], -1))\n",
    "        \n",
    "        results = {\n",
    "            \"transform\": \"original\",\n",
    "            \"featurizer\": self.featurizer.__name__,\n",
    "            \"num_samples\": len(self.t_dataset),\n",
    "            \"T_orig_acc\": self.orig_t_acc,\n",
    "            \"F_orig_acc\": self.orig_f_acc,\n",
    "            \"T_tran_acc\": 0,\n",
    "            \"F_tran_acc\": 0,\n",
    "            \"T_changed\": 0,\n",
    "            \"F_changed\": 0\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "            \n",
    "    def evaluate_transform(self, pipe):\n",
    "               \n",
    "        # pass data through the model\n",
    "        self.tran_t_preds = extract_probs(pipe(KeyDataset(self.tran_t_dataset, \"text\")))\n",
    "        self.tran_f_preds = extract_probs(pipe(KeyDataset(self.tran_f_dataset, \"text\")))\n",
    "        \n",
    "        # compute accuracy\n",
    "        self.tran_t_acc = compute_accuracy(\n",
    "            self.tran_t_preds, np.array(self.tran_t_dataset['label']))\n",
    "        self.tran_f_acc = compute_accuracy(\n",
    "            self.tran_f_preds, np.array(self.tran_f_dataset['label']))\n",
    "        \n",
    "        results = {\n",
    "            \"transform\": self.transform.__class__.__name__,\n",
    "            \"featurizer\": self.featurizer.__name__,\n",
    "            \"num_samples\": len(self.t_dataset),\n",
    "            \"T_orig_acc\": self.orig_t_acc,\n",
    "            \"F_orig_acc\": self.orig_f_acc,\n",
    "            \"T_tran_acc\": self.tran_t_acc,\n",
    "            \"F_tran_acc\": self.tran_f_acc,\n",
    "            \"T_changed\": self.t_changed,\n",
    "            \"F_changed\": self.f_changed\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_prediction_details(self):\n",
    "        # Feature DataFrame: T\n",
    "        t_df = pd.DataFrame(\n",
    "            [\n",
    "                f.t_dataset[\"text\"], \n",
    "                f.t_dataset[\"label\"],\n",
    "                f.orig_t_preds,\n",
    "                f.tran_t_dataset[\"text\"],\n",
    "                f.tran_t_dataset[\"label\"],\n",
    "                f.tran_t_preds,\n",
    "            ]).T\n",
    "        t_df.columns = ['orig_t_text', 'orig_t_label', 'orig_t_preds', \n",
    "                        'tran_t_text', 'tran_t_label', 'tran_t_preds']\n",
    "        \n",
    "        t_df['t_pred_diff'] = t_df.apply(lambda row: np.array(row['orig_t_preds']) - np.array(row['tran_t_preds']), axis=1)\n",
    "\n",
    "        # Feature DataFrame: F\n",
    "        f_df = pd.DataFrame(\n",
    "            [\n",
    "                f.f_dataset[\"text\"], \n",
    "                f.f_dataset[\"label\"],\n",
    "                f.orig_f_preds,\n",
    "                f.tran_f_dataset[\"text\"],\n",
    "                f.tran_f_dataset[\"label\"],\n",
    "                f.tran_f_preds,\n",
    "            ]).T\n",
    "        f_df.columns = ['orig_f_text', 'orig_f_label', 'orig_f_preds', \n",
    "                        'tran_f_text', 'tran_f_label', 'tran_f_preds']\n",
    "\n",
    "        f_df['f_pred_diff'] = f_df.apply(lambda row: np.array(row['orig_f_preds']) - np.array(row['tran_f_preds']), axis=1)\n",
    "        \n",
    "        return t_df, f_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f2937703",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizers = [    \n",
    "    contains_imperative,contains_exlamation,contains_negation,\n",
    "    contains_conjunctions,contains_interrogative_clause,contains_question,\n",
    "    contains_coreferences,contains_number,contains_accompanier,\n",
    "    contains_age,contains_beneficiary,contains_concession,\n",
    "    contains_condition,contains_consist_of,contains_degree,\n",
    "    contains_destination,contains_direction,contains_domain,\n",
    "    contains_duration,contains_example,contains_extent,\n",
    "    contains_frequency,contains_instrument,contains_location,\n",
    "    contains_manner,contains_medium,contains_mod,\n",
    "    contains_mode,contains_name,contains_ord,\n",
    "    contains_part,contains_path,contains_polarity,\n",
    "    contains_polite,contains_poss,contains_purpose,\n",
    "    contains_quant,contains_range,contains_scale,\n",
    "    contains_source,contains_subevent,contains_time,\n",
    "    contains_topic,contains_unit,contains_wiki\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "af530526",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de5ac7710124e59a8a86d680c080c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_imperative\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'hide new secretions from the parental units ', 'label': [1.0, 0.0]}\n",
      "F Feature: {'text': 'randolph ', 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_exlamation\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'no lika da ', 'label': [1.0, 0.0]}\n",
      "F Feature: {'text': \"a little too ponderous to work as shallow entertainment , not remotely incisive enough to qualify as drama , monsoon wedding serves mostly to whet one 's appetite for the bollywood films . \", 'label': [1.0, 0.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_negation\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'contains no wit , only labored gags ', 'label': [1.0, 0.0]}\n",
      "F Feature: {'text': 'right stuff ', 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_conjunctions\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'contains no wit , only labored gags ', 'label': [1.0, 0.0]}\n",
      "F Feature: {'text': 'warm water under a red bridge is a celebration of feminine energy , a tribute to the power of women to heal . ', 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_interrogative_clause\n",
      "Dataset Size: 78\n",
      "T Feature: {'text': 'the problem with the film is whether these ambitions , laudable in themselves , justify a theatrical simulation of the death camp of auschwitz ii-birkenau . ', 'label': [1.0, 0.0]}\n",
      "F Feature: {'text': 'immature and unappealing ', 'label': [1.0, 0.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_question\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': \"... a sour little movie at its core ; an exploration of the emptiness that underlay the relentless gaiety of the 1920 's ... the film 's ending has a `` what was it all for ? '' \", 'label': [1.0, 0.0]}\n",
      "F Feature: {'text': 'of ` ethnic cleansing ', 'label': [1.0, 0.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_coreferences\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': \"proves once again he has n't lost his touch , bringing off a superb performance in an admittedly middling film . \", 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': \"has always been part of for the most part wilde 's droll whimsy helps `` being earnest '' overcome its weaknesses and parker 's creative interference ... \", 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_number\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': \"a depressed fifteen-year-old 's suicidal poetry \", 'label': [1.0, 0.0]}\n",
      "F Feature: {'text': \"it 's supposed to be a romantic comedy - it suffers from too much norma rae and not enough pretty woman . \", 'label': [1.0, 0.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_accompanier\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': \"build some robots , haul 'em to the theater with you for the late show , and put on your own mystery science theatre 3000 tribute to what is almost certainly going to go down as the worst -- and only -- killer website movie of this or any other year \", 'label': [1.0, 0.0]}\n",
      "F Feature: {'text': 'black hawk down with more heart ', 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_age\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': \"a depressed fifteen-year-old 's suicidal poetry \", 'label': [1.0, 0.0]}\n",
      "F Feature: {'text': 'builds gradually until you feel fully embraced by this gentle comedy . ', 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_beneficiary\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'pays earnest homage to turntablists ', 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': 'an unsophisticated sci-fi drama that takes itself all too seriously . ', 'label': [1.0, 0.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_concession\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'some movies suck you in despite their flaws , ', 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': 'only open new wounds ', 'label': [1.0, 0.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_condition\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'if anything , see it for karen black , who camps up a storm as a fringe feminist conspiracy theorist named dirty dick . ', 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': 'virtually nothing to show ', 'label': [1.0, 0.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_consist_of\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'enriched by an imaginatively mixed cast of antic spirits ', 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': 'the characters , cast in impossibly contrived situations , are totally estranged from reality . ', 'label': [1.0, 0.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_degree\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'that loves its characters and communicates something rather beautiful about human nature ', 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': ', home movie will leave you wanting more , not to mention leaving you with some laughs and a smile on your face . ', 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_destination\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'can open the door to liberation . ', 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': \"the little girls understand , and mccracken knows that 's all that matters . \", 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_direction\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'fashioning an engrossing entertainment out ', 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': \"the film runs on a little longer than it needs to -- muccino either does n't notice when his story ends or just ca n't tear himself away from the characters -- \", 'label': [1.0, 0.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_domain\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'the plot is nothing but boilerplate clichés from start to finish , ', 'label': [1.0, 0.0]}\n",
      "F Feature: {'text': 'thank ', 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_duration\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'remains utterly satisfied to remain the same throughout ', 'label': [1.0, 0.0]}\n",
      "F Feature: {'text': 'plumbs uncharted depths of stupidity , incoherence and sub-sophomoric sexual banter . ', 'label': [1.0, 0.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_example\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'demonstrates that the director of such hollywood blockbusters as patriot games can still turn out a small , personal film with an emotional wallop . ', 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': \", it 's because there 's no discernible feeling beneath the chest hair \", 'label': [1.0, 0.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_extent\n",
      "Dataset Size: 92\n",
      "T Feature: {'text': 'wide-awake all the way through ', 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': \"one of the year 's best films \", 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_frequency\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'will find little of interest in this film , which is often preachy and poorly acted ', 'label': [1.0, 0.0]}\n",
      "F Feature: {'text': 'luridly graphic and ', 'label': [1.0, 0.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_instrument\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': \"delivers what it promises : a look at the `` wild ride '' that ensues when brash young men set out to conquer the online world with laptops , cell phones and sketchy business plans \", 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': 'in welcome perspective ', 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_location\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': \"the part where nothing 's happening , \", 'label': [1.0, 0.0]}\n",
      "F Feature: {'text': 'a journey spanning nearly three decades of bittersweet camaraderie and history , in which we feel that we truly know what makes holly and marina tick ', 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_manner\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'demonstrates that the director of such hollywood blockbusters as patriot games can still turn out a small , personal film with an emotional wallop . ', 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': '... the efforts of its star , kline , to lend some dignity to a dumb story are for naught . ', 'label': [1.0, 0.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_medium\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': \"build some robots , haul 'em to the theater with you for the late show , and put on your own mystery science theatre 3000 tribute to what is almost certainly going to go down as the worst -- and only -- killer website movie of this or any other year \", 'label': [1.0, 0.0]}\n",
      "F Feature: {'text': 'prepare ', 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_mod\n",
      "Dataset Size: 96\n",
      "T Feature: {'text': 'contains no wit , only labored gags ', 'label': [1.0, 0.0]}\n",
      "F Feature: {'text': 'far less sophisticated and ', 'label': [1.0, 0.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_mode\n",
      "Only 0 inputs contain the feature, skipping for insufficient data...\n",
      "Featurizer: contains_name\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'on the worst revenge-of-the-nerds clichés the filmmakers could dredge up ', 'label': [1.0, 0.0]}\n",
      "F Feature: {'text': 'hip hop beat ', 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_ord\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'covers this territory with wit and originality , suggesting that with his fourth feature ', 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': 'more than ably ', 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_part\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': \"swimming is above all about a young woman 's face , and by casting an actress whose face projects that woman 's doubts and yearnings , it succeeds . \", 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': 'heart as important as humor ', 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_path\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'he appears miserable throughout as he swaggers through his scenes ', 'label': [1.0, 0.0]}\n",
      "F Feature: {'text': \"it 's funny and human and really pretty damned wonderful , all at once . \", 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_polarity\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'have i seen a film so willing to champion the fallibility of the human heart ', 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': 'measured against practically any like-themed film other than its oscar-sweeping franchise predecessor the silence of the lambs , red dragon rates as an exceptional thriller . ', 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_polite\n",
      "Only 0 inputs contain the feature, skipping for insufficient data...\n",
      "Featurizer: contains_poss\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'that loves its characters and communicates something rather beautiful about human nature ', 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': 'skip this dreck , ', 'label': [1.0, 0.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_purpose\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'very good viewing alternative ', 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': \"'s no surprise that as a director washington demands and receives excellent performances , \", 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_quant\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'lend some dignity to a dumb story ', 'label': [1.0, 0.0]}\n",
      "F Feature: {'text': 'a markedly inactive film ', 'label': [1.0, 0.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_range\n",
      "Dataset Size: 7\n",
      "T Feature: {'text': \"the first bond movie in ages that is n't fake fun \", 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': 'like the english patient and the unbearable lightness of being ', 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_scale\n",
      "Only 1 inputs contain the feature, skipping for insufficient data...\n",
      "Featurizer: contains_source\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'hate to tear your eyes away from the images long enough to read the subtitles ', 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': 'seems timely and important ', 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_subevent\n",
      "Dataset Size: 89\n",
      "T Feature: {'text': 'provide the funniest moments in this oddly sweet comedy about jokester highway patrolmen ', 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': 'though overall an overwhelmingly positive portrayal ', 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_time\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': \"for those moviegoers who complain that ` they do n't make movies like they used to anymore \", 'label': [1.0, 0.0]}\n",
      "F Feature: {'text': 'things will turn out okay ', 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_topic\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': 'that loves its characters and communicates something rather beautiful about human nature ', 'label': [0.0, 1.0]}\n",
      "F Feature: {'text': 'human nature is a goofball movie , in the way that malkovich was , but it tries too hard ', 'label': [1.0, 0.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_unit\n",
      "Dataset Size: 100\n",
      "T Feature: {'text': \"a depressed fifteen-year-old 's suicidal poetry \", 'label': [1.0, 0.0]}\n",
      "F Feature: {'text': 'an admittedly middling film ', 'label': [0.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\dpml\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer: contains_wiki\n",
      "Only 0 inputs contain the feature, skipping for insufficient data...\n"
     ]
    }
   ],
   "source": [
    "f = AMRBooleanFeature(dataset, amrs)\n",
    "\n",
    "feature_results = {}\n",
    "for featurizer in tqdm(featurizers):\n",
    "    \n",
    "    # feature info\n",
    "    feature_name = featurizer.__name__\n",
    "    print(f\"Featurizer: {feature_name}\")\n",
    "\n",
    "    # create feature datasets\n",
    "    f.extract_data_containing_feature(featurizer, 100)\n",
    "    if not f.t_dataset:\n",
    "        continue\n",
    "    print(f\"Dataset Size: {len(f.t_dataset)}\")\n",
    "    print(f\"T Feature: {f.t_dataset[0]}\")\n",
    "    print(f\"F Feature: {f.f_dataset[0]}\")\n",
    "    \n",
    "    # evaluation\n",
    "    results = []\n",
    "    # evaluate original\n",
    "    results.append(f.evaluate_original(pipe))\n",
    "    # evaluate transformations\n",
    "    for t in ts:\n",
    "        f.generate_transformed_datasets(t)\n",
    "        result = f.evaluate_transform(pipe)\n",
    "        # print(result)\n",
    "        t_df, f_df = f.get_prediction_details()\n",
    "        result['t_df'] = t_df\n",
    "        result['f_df'] = f_df\n",
    "        results.append(result)\n",
    "        \n",
    "    df = pd.DataFrame(results)\n",
    "    df['T_diff'] = df['T_orig_acc'] - df['T_tran_acc']\n",
    "    df['F_diff'] = df['F_orig_acc'] - df['F_tran_acc']\n",
    "        \n",
    "    feature_results[feature_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e171e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionary as pickle file\n",
    "pickle_out = open('analysis_results.pkl', 'wb')\n",
    "pickle.dump(feature_results, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a7f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dictionary from pickle file\n",
    "pickle_in = open('analysis_results.pkl', 'rb')\n",
    "new_dict = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b251df89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transform</th>\n",
       "      <th>featurizer</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>T_orig_acc</th>\n",
       "      <th>F_orig_acc</th>\n",
       "      <th>T_tran_acc</th>\n",
       "      <th>F_tran_acc</th>\n",
       "      <th>T_changed</th>\n",
       "      <th>F_changed</th>\n",
       "      <th>t_df</th>\n",
       "      <th>f_df</th>\n",
       "      <th>T_diff</th>\n",
       "      <th>F_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExpandContractions</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ContractContractions</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AddPositiveEmoji</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AddNegativeEmoji</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AddNeutralEmoji</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Demojify</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RemovePositiveEmoji</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RemoveNegativeEmoji</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RemoveNeutralEmoji</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ChangeLocation</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ChangeName</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>InsertPositivePhrase</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>InsertNegativePhrase</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomInsertion</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>InsertPunctuationMarks</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AddPositiveLink</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AddNegativeLink</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ImportLinkText</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AddNegation</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RemoveNegation</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomCharDel</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomCharInsert</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomCharSubst</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomCharSwap</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomSwapQwerty</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.86</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ChangeNumber</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ChangeSynonym</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ChangeAntonym</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.84</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ChangeHyponym</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.83</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ChangeHypernym</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>WordDeletion</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>HomoglyphSwap</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>RandomSwap</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>TextMix</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SentMix</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>WordMix</td>\n",
       "      <td>contains_negation</td>\n",
       "      <td>100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>orig...</td>\n",
       "      <td>orig...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 transform         featurizer  num_samples  T_orig_acc  \\\n",
       "0                 original  contains_negation          100        0.98   \n",
       "1       ExpandContractions  contains_negation          100        0.98   \n",
       "2     ContractContractions  contains_negation          100        0.98   \n",
       "3         AddPositiveEmoji  contains_negation          100        0.98   \n",
       "4         AddNegativeEmoji  contains_negation          100        0.98   \n",
       "5          AddNeutralEmoji  contains_negation          100        0.98   \n",
       "6                 Demojify  contains_negation          100        0.98   \n",
       "7      RemovePositiveEmoji  contains_negation          100        0.98   \n",
       "8      RemoveNegativeEmoji  contains_negation          100        0.98   \n",
       "9       RemoveNeutralEmoji  contains_negation          100        0.98   \n",
       "10          ChangeLocation  contains_negation          100        0.98   \n",
       "11              ChangeName  contains_negation          100        0.98   \n",
       "12    InsertPositivePhrase  contains_negation          100        0.98   \n",
       "13    InsertNegativePhrase  contains_negation          100        0.98   \n",
       "14         RandomInsertion  contains_negation          100        0.98   \n",
       "15  InsertPunctuationMarks  contains_negation          100        0.98   \n",
       "16         AddPositiveLink  contains_negation          100        0.98   \n",
       "17         AddNegativeLink  contains_negation          100        0.98   \n",
       "18          ImportLinkText  contains_negation          100        0.98   \n",
       "19             AddNegation  contains_negation          100        0.98   \n",
       "20          RemoveNegation  contains_negation          100        0.98   \n",
       "21           RandomCharDel  contains_negation          100        0.98   \n",
       "22        RandomCharInsert  contains_negation          100        0.98   \n",
       "23         RandomCharSubst  contains_negation          100        0.98   \n",
       "24          RandomCharSwap  contains_negation          100        0.98   \n",
       "25        RandomSwapQwerty  contains_negation          100        0.98   \n",
       "26            ChangeNumber  contains_negation          100        0.98   \n",
       "27           ChangeSynonym  contains_negation          100        0.98   \n",
       "28           ChangeAntonym  contains_negation          100        0.98   \n",
       "29           ChangeHyponym  contains_negation          100        0.98   \n",
       "30          ChangeHypernym  contains_negation          100        0.98   \n",
       "31            WordDeletion  contains_negation          100        0.98   \n",
       "32           HomoglyphSwap  contains_negation          100        0.98   \n",
       "33              RandomSwap  contains_negation          100        0.98   \n",
       "34                 TextMix  contains_negation          100        0.98   \n",
       "35                 SentMix  contains_negation          100        0.98   \n",
       "36                 WordMix  contains_negation          100        0.98   \n",
       "\n",
       "    F_orig_acc  T_tran_acc  F_tran_acc  T_changed  F_changed  \\\n",
       "0         0.99        0.00        0.00       0.00       0.00   \n",
       "1         0.99        0.98        0.99       0.00       0.00   \n",
       "2         0.99        0.97        0.99       0.10       0.03   \n",
       "3         0.99        0.98        0.98       1.00       1.00   \n",
       "4         0.99        0.98        0.98       1.00       1.00   \n",
       "5         0.99        0.98        0.98       1.00       1.00   \n",
       "6         0.99        0.98        0.99       0.00       0.00   \n",
       "7         0.99        0.98        0.99       0.00       0.00   \n",
       "8         0.99        0.98        0.99       0.00       0.00   \n",
       "9         0.99        0.98        0.99       0.00       0.00   \n",
       "10        0.99        0.98        0.98       0.05       0.04   \n",
       "11        0.99        0.98        0.99       0.06       0.00   \n",
       "12        0.99        0.68        0.81       1.00       1.00   \n",
       "13        0.99        0.90        0.85       1.00       1.00   \n",
       "14        0.99        0.96        0.97       1.00       0.94   \n",
       "15        0.99        0.93        0.95       1.00       1.00   \n",
       "16        0.99        0.97        0.95       1.00       1.00   \n",
       "17        0.99        0.96        0.84       1.00       1.00   \n",
       "18        0.99        0.98        0.99       0.00       0.00   \n",
       "19        0.99        0.92        0.83       0.33       0.33   \n",
       "20        0.99        0.79        0.99       0.42       0.00   \n",
       "21        0.99        0.91        0.92       1.00       1.00   \n",
       "22        0.99        0.94        0.94       1.00       1.00   \n",
       "23        0.99        0.92        0.94       0.99       0.98   \n",
       "24        0.99        0.92        0.93       0.99       1.00   \n",
       "25        0.99        0.89        0.96       0.77       0.86   \n",
       "26        0.99        0.98        0.98       0.01       0.04   \n",
       "27        0.99        0.80        0.85       0.95       0.91   \n",
       "28        0.99        0.68        0.65       0.93       0.84   \n",
       "29        0.99        0.86        0.87       0.88       0.83   \n",
       "30        0.99        0.76        0.83       0.89       0.90   \n",
       "31        0.99        0.81        0.95       1.00       0.94   \n",
       "32        0.99        0.71        0.58       1.00       1.00   \n",
       "33        0.99        0.95        0.97       1.00       1.00   \n",
       "34        0.99        0.79        0.84       1.00       1.00   \n",
       "35        0.99        0.82        0.88       1.00       1.00   \n",
       "36        0.99        0.72        0.75       1.00       1.00   \n",
       "\n",
       "                                                 t_df  \\\n",
       "0                                                 NaN   \n",
       "1                                             orig...   \n",
       "2                                             orig...   \n",
       "3                                             orig...   \n",
       "4                                             orig...   \n",
       "5                                             orig...   \n",
       "6                                             orig...   \n",
       "7                                             orig...   \n",
       "8                                             orig...   \n",
       "9                                             orig...   \n",
       "10                                            orig...   \n",
       "11                                            orig...   \n",
       "12                                            orig...   \n",
       "13                                            orig...   \n",
       "14                                            orig...   \n",
       "15                                            orig...   \n",
       "16                                            orig...   \n",
       "17                                            orig...   \n",
       "18                                            orig...   \n",
       "19                                            orig...   \n",
       "20                                            orig...   \n",
       "21                                            orig...   \n",
       "22                                            orig...   \n",
       "23                                            orig...   \n",
       "24                                            orig...   \n",
       "25                                            orig...   \n",
       "26                                            orig...   \n",
       "27                                            orig...   \n",
       "28                                            orig...   \n",
       "29                                            orig...   \n",
       "30                                            orig...   \n",
       "31                                            orig...   \n",
       "32                                            orig...   \n",
       "33                                            orig...   \n",
       "34                                            orig...   \n",
       "35                                            orig...   \n",
       "36                                            orig...   \n",
       "\n",
       "                                                 f_df  T_diff  F_diff  \n",
       "0                                                 NaN    0.98    0.99  \n",
       "1                                             orig...    0.00    0.00  \n",
       "2                                             orig...    0.01    0.00  \n",
       "3                                             orig...    0.00    0.01  \n",
       "4                                             orig...    0.00    0.01  \n",
       "5                                             orig...    0.00    0.01  \n",
       "6                                             orig...    0.00    0.00  \n",
       "7                                             orig...    0.00    0.00  \n",
       "8                                             orig...    0.00    0.00  \n",
       "9                                             orig...    0.00    0.00  \n",
       "10                                            orig...    0.00    0.01  \n",
       "11                                            orig...    0.00    0.00  \n",
       "12                                            orig...    0.30    0.18  \n",
       "13                                            orig...    0.08    0.14  \n",
       "14                                            orig...    0.02    0.02  \n",
       "15                                            orig...    0.05    0.04  \n",
       "16                                            orig...    0.01    0.04  \n",
       "17                                            orig...    0.02    0.15  \n",
       "18                                            orig...    0.00    0.00  \n",
       "19                                            orig...    0.06    0.16  \n",
       "20                                            orig...    0.19    0.00  \n",
       "21                                            orig...    0.07    0.07  \n",
       "22                                            orig...    0.04    0.05  \n",
       "23                                            orig...    0.06    0.05  \n",
       "24                                            orig...    0.06    0.06  \n",
       "25                                            orig...    0.09    0.03  \n",
       "26                                            orig...    0.00    0.01  \n",
       "27                                            orig...    0.18    0.14  \n",
       "28                                            orig...    0.30    0.34  \n",
       "29                                            orig...    0.12    0.12  \n",
       "30                                            orig...    0.22    0.16  \n",
       "31                                            orig...    0.17    0.04  \n",
       "32                                            orig...    0.27    0.41  \n",
       "33                                            orig...    0.03    0.02  \n",
       "34                                            orig...    0.19    0.15  \n",
       "35                                            orig...    0.16    0.11  \n",
       "36                                            orig...    0.26    0.24  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_results['contains_negation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85c75eb",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "Note: Significant differences are any greater than 10%\n",
    "\n",
    "1. Relative to a no-transform baseline, the presence of a question in a text leads to more stable behavior in sibyl transforms.\n",
    "   - Twelve (12) transforms induce significant accuracy changes for texts not containing a question.\n",
    "   - Only six (6) transforms induce significant accuracy changes for texts containing a question.  \n",
    "2. Four (4) transforms exhibit significant differences in impact for different `contains_question` features.\n",
    "3. Six (6) transforms did not apply to the sampled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f625574a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transform</th>\n",
       "      <th>featurizer</th>\n",
       "      <th>T_orig_acc</th>\n",
       "      <th>F_orig_acc</th>\n",
       "      <th>T_tran_acc</th>\n",
       "      <th>F_tran_acc</th>\n",
       "      <th>T_changed</th>\n",
       "      <th>F_changed</th>\n",
       "      <th>t_df</th>\n",
       "      <th>f_df</th>\n",
       "      <th>T_diff</th>\n",
       "      <th>F_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>InsertPositivePhrase</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.586022</td>\n",
       "      <td>0.849462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.413978</td>\n",
       "      <td>0.145161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ChangeAntonym</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.650538</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.876344</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.344086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>HomoglyphSwap</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.510753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.483871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>TextMix</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.897849</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.102151</td>\n",
       "      <td>0.161290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SentMix</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.897849</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.102151</td>\n",
       "      <td>0.172043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>WordMix</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.811828</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.188172</td>\n",
       "      <td>0.204301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               transform         featurizer  T_orig_acc  F_orig_acc  \\\n",
       "0               original  contains_question         1.0    0.994624   \n",
       "12  InsertPositivePhrase  contains_question         1.0    0.994624   \n",
       "28         ChangeAntonym  contains_question         1.0    0.994624   \n",
       "32         HomoglyphSwap  contains_question         1.0    0.994624   \n",
       "34               TextMix  contains_question         1.0    0.994624   \n",
       "35               SentMix  contains_question         1.0    0.994624   \n",
       "36               WordMix  contains_question         1.0    0.994624   \n",
       "\n",
       "    T_tran_acc  F_tran_acc  T_changed  F_changed  \\\n",
       "0     0.000000    0.000000   0.000000   0.000000   \n",
       "12    0.586022    0.849462   1.000000   1.000000   \n",
       "28    0.870968    0.650538   0.951613   0.876344   \n",
       "32    0.838710    0.510753   1.000000   1.000000   \n",
       "34    0.897849    0.833333   1.000000   1.000000   \n",
       "35    0.897849    0.822581   1.000000   1.000000   \n",
       "36    0.811828    0.790323   1.000000   1.000000   \n",
       "\n",
       "                                                 t_df  \\\n",
       "0                                                 NaN   \n",
       "12                                             ori...   \n",
       "28                                             ori...   \n",
       "32                                             ori...   \n",
       "34                                             ori...   \n",
       "35                                             ori...   \n",
       "36                                             ori...   \n",
       "\n",
       "                                                 f_df    T_diff    F_diff  \n",
       "0                                                 NaN  1.000000  0.994624  \n",
       "12                                             ori...  0.413978  0.145161  \n",
       "28                                             ori...  0.129032  0.344086  \n",
       "32                                             ori...  0.161290  0.483871  \n",
       "34                                             ori...  0.102151  0.161290  \n",
       "35                                             ori...  0.102151  0.172043  \n",
       "36                                             ori...  0.188172  0.204301  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# significant impact \n",
    "df[df['T_diff'] > 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "dada9a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transform</th>\n",
       "      <th>featurizer</th>\n",
       "      <th>T_orig_acc</th>\n",
       "      <th>F_orig_acc</th>\n",
       "      <th>T_tran_acc</th>\n",
       "      <th>F_tran_acc</th>\n",
       "      <th>T_changed</th>\n",
       "      <th>F_changed</th>\n",
       "      <th>t_df</th>\n",
       "      <th>f_df</th>\n",
       "      <th>T_diff</th>\n",
       "      <th>F_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>InsertPositivePhrase</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.586022</td>\n",
       "      <td>0.849462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.413978</td>\n",
       "      <td>0.145161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>InsertNegativePhrase</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.252688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AddNegativeLink</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.881720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>0.112903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AddNegation</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.973118</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.435484</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>0.123656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ChangeSynonym</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.908602</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.908602</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.091398</td>\n",
       "      <td>0.155914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ChangeAntonym</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.650538</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.876344</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.344086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ChangeHyponym</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.924731</td>\n",
       "      <td>0.849462</td>\n",
       "      <td>0.956989</td>\n",
       "      <td>0.844086</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.075269</td>\n",
       "      <td>0.145161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ChangeHypernym</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.930108</td>\n",
       "      <td>0.876344</td>\n",
       "      <td>0.956989</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.069892</td>\n",
       "      <td>0.118280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>HomoglyphSwap</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.510753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.483871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>TextMix</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.897849</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.102151</td>\n",
       "      <td>0.161290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SentMix</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.897849</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.102151</td>\n",
       "      <td>0.172043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>WordMix</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.811828</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.188172</td>\n",
       "      <td>0.204301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               transform         featurizer  T_orig_acc  F_orig_acc  \\\n",
       "0               original  contains_question         1.0    0.994624   \n",
       "12  InsertPositivePhrase  contains_question         1.0    0.994624   \n",
       "13  InsertNegativePhrase  contains_question         1.0    0.994624   \n",
       "17       AddNegativeLink  contains_question         1.0    0.994624   \n",
       "19           AddNegation  contains_question         1.0    0.994624   \n",
       "27         ChangeSynonym  contains_question         1.0    0.994624   \n",
       "28         ChangeAntonym  contains_question         1.0    0.994624   \n",
       "29         ChangeHyponym  contains_question         1.0    0.994624   \n",
       "30        ChangeHypernym  contains_question         1.0    0.994624   \n",
       "32         HomoglyphSwap  contains_question         1.0    0.994624   \n",
       "34               TextMix  contains_question         1.0    0.994624   \n",
       "35               SentMix  contains_question         1.0    0.994624   \n",
       "36               WordMix  contains_question         1.0    0.994624   \n",
       "\n",
       "    T_tran_acc  F_tran_acc  T_changed  F_changed  \\\n",
       "0     0.000000    0.000000   0.000000   0.000000   \n",
       "12    0.586022    0.849462   1.000000   1.000000   \n",
       "13    0.935484    0.741935   1.000000   1.000000   \n",
       "17    0.951613    0.881720   1.000000   1.000000   \n",
       "19    0.973118    0.870968   0.435484   0.322581   \n",
       "27    0.908602    0.838710   0.951613   0.908602   \n",
       "28    0.870968    0.650538   0.951613   0.876344   \n",
       "29    0.924731    0.849462   0.956989   0.844086   \n",
       "30    0.930108    0.876344   0.956989   0.887097   \n",
       "32    0.838710    0.510753   1.000000   1.000000   \n",
       "34    0.897849    0.833333   1.000000   1.000000   \n",
       "35    0.897849    0.822581   1.000000   1.000000   \n",
       "36    0.811828    0.790323   1.000000   1.000000   \n",
       "\n",
       "                                                 t_df  \\\n",
       "0                                                 NaN   \n",
       "12                                             ori...   \n",
       "13                                             ori...   \n",
       "17                                             ori...   \n",
       "19                                             ori...   \n",
       "27                                             ori...   \n",
       "28                                             ori...   \n",
       "29                                             ori...   \n",
       "30                                             ori...   \n",
       "32                                             ori...   \n",
       "34                                             ori...   \n",
       "35                                             ori...   \n",
       "36                                             ori...   \n",
       "\n",
       "                                                 f_df    T_diff    F_diff  \n",
       "0                                                 NaN  1.000000  0.994624  \n",
       "12                                             ori...  0.413978  0.145161  \n",
       "13                                             ori...  0.064516  0.252688  \n",
       "17                                             ori...  0.048387  0.112903  \n",
       "19                                             ori...  0.026882  0.123656  \n",
       "27                                             ori...  0.091398  0.155914  \n",
       "28                                             ori...  0.129032  0.344086  \n",
       "29                                             ori...  0.075269  0.145161  \n",
       "30                                             ori...  0.069892  0.118280  \n",
       "32                                             ori...  0.161290  0.483871  \n",
       "34                                             ori...  0.102151  0.161290  \n",
       "35                                             ori...  0.102151  0.172043  \n",
       "36                                             ori...  0.188172  0.204301  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['F_diff'] > 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "75d43b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transform</th>\n",
       "      <th>featurizer</th>\n",
       "      <th>T_orig_acc</th>\n",
       "      <th>F_orig_acc</th>\n",
       "      <th>T_tran_acc</th>\n",
       "      <th>F_tran_acc</th>\n",
       "      <th>T_changed</th>\n",
       "      <th>F_changed</th>\n",
       "      <th>t_df</th>\n",
       "      <th>f_df</th>\n",
       "      <th>T_diff</th>\n",
       "      <th>F_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>InsertPositivePhrase</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.586022</td>\n",
       "      <td>0.849462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.413978</td>\n",
       "      <td>0.145161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>InsertNegativePhrase</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.252688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ChangeAntonym</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.650538</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.876344</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.344086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>HomoglyphSwap</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.510753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ori...</td>\n",
       "      <td>ori...</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.483871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               transform         featurizer  T_orig_acc  F_orig_acc  \\\n",
       "12  InsertPositivePhrase  contains_question         1.0    0.994624   \n",
       "13  InsertNegativePhrase  contains_question         1.0    0.994624   \n",
       "28         ChangeAntonym  contains_question         1.0    0.994624   \n",
       "32         HomoglyphSwap  contains_question         1.0    0.994624   \n",
       "\n",
       "    T_tran_acc  F_tran_acc  T_changed  F_changed  \\\n",
       "12    0.586022    0.849462   1.000000   1.000000   \n",
       "13    0.935484    0.741935   1.000000   1.000000   \n",
       "28    0.870968    0.650538   0.951613   0.876344   \n",
       "32    0.838710    0.510753   1.000000   1.000000   \n",
       "\n",
       "                                                 t_df  \\\n",
       "12                                             ori...   \n",
       "13                                             ori...   \n",
       "28                                             ori...   \n",
       "32                                             ori...   \n",
       "\n",
       "                                                 f_df    T_diff    F_diff  \n",
       "12                                             ori...  0.413978  0.145161  \n",
       "13                                             ori...  0.064516  0.252688  \n",
       "28                                             ori...  0.129032  0.344086  \n",
       "32                                             ori...  0.161290  0.483871  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# significant impact difference by feature\n",
    "df[abs(df['T_diff'] - df['F_diff']) > 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "edce5254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transform</th>\n",
       "      <th>featurizer</th>\n",
       "      <th>T_orig_acc</th>\n",
       "      <th>F_orig_acc</th>\n",
       "      <th>T_tran_acc</th>\n",
       "      <th>F_tran_acc</th>\n",
       "      <th>T_changed</th>\n",
       "      <th>F_changed</th>\n",
       "      <th>T_diff</th>\n",
       "      <th>F_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExpandContractions</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Demojify</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RemovePositiveEmoji</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RemoveNegativeEmoji</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RemoveNeutralEmoji</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ImportLinkText</td>\n",
       "      <td>contains_question</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              transform         featurizer  T_orig_acc  F_orig_acc  \\\n",
       "0              original  contains_question         1.0         1.0   \n",
       "1    ExpandContractions  contains_question         1.0         1.0   \n",
       "6              Demojify  contains_question         1.0         1.0   \n",
       "7   RemovePositiveEmoji  contains_question         1.0         1.0   \n",
       "8   RemoveNegativeEmoji  contains_question         1.0         1.0   \n",
       "9    RemoveNeutralEmoji  contains_question         1.0         1.0   \n",
       "18       ImportLinkText  contains_question         1.0         1.0   \n",
       "\n",
       "    T_tran_acc  F_tran_acc  T_changed  F_changed  T_diff  F_diff  \n",
       "0          0.0         0.0        0.0        0.0     1.0     1.0  \n",
       "1          1.0         1.0        0.0        0.0     0.0     0.0  \n",
       "6          1.0         1.0        0.0        0.0     0.0     0.0  \n",
       "7          1.0         1.0        0.0        0.0     0.0     0.0  \n",
       "8          1.0         1.0        0.0        0.0     0.0     0.0  \n",
       "9          1.0         1.0        0.0        0.0     0.0     0.0  \n",
       "18         1.0         1.0        0.0        0.0     0.0     0.0  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inapplicable transforms\n",
    "df[(df['T_changed'] == 0) & (df['F_changed'] == 0)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "418cf952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"... a sour little movie at its core ; an exploration of the emptiness that underlay the relentless gaiety of the 1920 's ... the film 's ending has a `` what was it all for ? '' \""
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# InsertPositivePhrase Details\n",
    "df.iloc[12].t_df.iloc[0].orig_t_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7530cdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.0]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[12].t_df.iloc[0].orig_t_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "cb22fe6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"... a sour little movie at its core ; an exploration of the emptiness that underlay the relentless gaiety of the 1920 's ... the film 's ending has a `` what was it all for ? ''  That being said, I loved it.\""
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[12].t_df.iloc[0].tran_t_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e09198ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8640776699029126, 0.13592233009708743]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[12].t_df.iloc[0].tran_t_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d4dc4648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99622107e-01, 3.77893448e-04])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[12].t_df.iloc[0].orig_t_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f4f5c533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96844983, 0.03155017])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[12].t_df.iloc[0].tran_t_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ea2265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
