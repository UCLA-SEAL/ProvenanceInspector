{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuWi1REPD_Ux"
   },
   "source": [
    "# DPML | Latency Replay\n",
    "\n",
    "In this notebook, we investigate the reproducibility of transformation sequences captured by `dpml`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9Zs0hYFFIYf"
   },
   "source": [
    "## Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t8_koamxFHfR",
    "outputId": "e892403a-70b8-4728-ec18-c31ee7e81580"
   },
   "outputs": [],
   "source": [
    "from lineage import LeBatch\n",
    "\n",
    "from sibyl import *\n",
    "from datasets import load_dataset\n",
    "\n",
    "import time\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktCv--paFOqG"
   },
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\Fabrice\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"glue\", \"sst2\", split=\"train[:100]\")\n",
    "dataset = dataset.rename_column('sentence', 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Routine to be Tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = SibylTransformer(\"sentiment\", num_INV = 2, num_SIB = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf4cb93a29a4217a02a9d6169b5d948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 39.337 seconds\n"
     ]
    }
   ],
   "source": [
    "text, label = dataset['text'], dataset['label'] \n",
    "new_text, new_label = [], []\n",
    "\n",
    "batch_size= 10\n",
    "\n",
    "startTime = time.perf_counter()\n",
    "for i in tqdm(range(0, len(label), batch_size)):\n",
    "    text_batch = text[i:i+batch_size]\n",
    "    label_batch = label[i:i+batch_size]\n",
    "    batch = (text_batch, label_batch)\n",
    "    new_records = LeBatch(batch).apply(transform)\n",
    "print('Elapsed time: {:6.3f} seconds'.format(time.perf_counter() - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<LeRecord:\n",
       " \t text=\"that 's so sloppily written and cast that you can not believe anyone more central to the creation of bugsy than the caterer\",\n",
       " \t target=\"[0.75, 0.25]\",\n",
       " \t le_attrs={'transformation_provenance': <TransformationProvenance: {(0, \"{'class': 'SibylTransformer', 'task': 'sentiment', 'num_classes': 2, 'multiplier': 1, 'num_INV': 2, 'num_SIB': 2}\")}>, 'feature_provenance': <FeatureProvenance[edit_seq] set()>, 'granularity': 'word'}>,\n",
       " <LeRecord:\n",
       " \t text=\"alternating between facetious comic parody and pulp melodrama , this smart-aleck movie ... tosses around some intriguing questions about the difference between human and android life\",\n",
       " \t target=\"[0.25, 0.75]\",\n",
       " \t le_attrs={'transformation_provenance': <TransformationProvenance: {(0, \"{'class': 'SibylTransformer', 'task': 'sentiment', 'num_classes': 2, 'multiplier': 1, 'num_INV': 2, 'num_SIB': 2}\")}>, 'feature_provenance': <FeatureProvenance[edit_seq] set()>, 'granularity': 'word'}>,\n",
       " <LeRecord:\n",
       " \t text=\"strung-together moments\",\n",
       " \t target=\"[0.75, 0.25]\",\n",
       " \t le_attrs={'transformation_provenance': <TransformationProvenance: {(0, \"{'class': 'SibylTransformer', 'task': 'sentiment', 'num_classes': 2, 'multiplier': 1, 'num_INV': 2, 'num_SIB': 2}\")}>, 'feature_provenance': <FeatureProvenance[edit_seq] set()>, 'granularity': 'word'}>,\n",
       " <LeRecord:\n",
       " \t text=\", generous and subversive artworks\",\n",
       " \t target=\"[0.25, 0.75]\",\n",
       " \t le_attrs={'transformation_provenance': <TransformationProvenance: {(0, \"{'class': 'SibylTransformer', 'task': 'sentiment', 'num_classes': 2, 'multiplier': 1, 'num_INV': 2, 'num_SIB': 2}\")}>, 'feature_provenance': <FeatureProvenance[edit_seq] set()>, 'granularity': 'word'}>,\n",
       " <LeRecord:\n",
       " \t text=\"it does n't follow the stale , standard , connect-the-dots storyline which has become commonplace in movies that explore the seamy underbelly of the criminal world\",\n",
       " \t target=\"[0.25, 0.75]\",\n",
       " \t le_attrs={'transformation_provenance': <TransformationProvenance: {(0, \"{'class': 'SibylTransformer', 'task': 'sentiment', 'num_classes': 2, 'multiplier': 1, 'num_INV': 2, 'num_SIB': 2}\")}>, 'feature_provenance': <FeatureProvenance[edit_seq] set()>, 'granularity': 'word'}>,\n",
       " <LeRecord:\n",
       " \t text=\"funny yet\",\n",
       " \t target=\"[0.25, 0.75]\",\n",
       " \t le_attrs={'transformation_provenance': <TransformationProvenance: {(0, \"{'class': 'SibylTransformer', 'task': 'sentiment', 'num_classes': 2, 'multiplier': 1, 'num_INV': 2, 'num_SIB': 2}\")}>, 'feature_provenance': <FeatureProvenance[edit_seq] set()>, 'granularity': 'word'}>,\n",
       " <LeRecord:\n",
       " \t text=\"overbearing and over-the-top\",\n",
       " \t target=\"[0.75, 0.25]\",\n",
       " \t le_attrs={'transformation_provenance': <TransformationProvenance: {(0, \"{'class': 'SibylTransformer', 'task': 'sentiment', 'num_classes': 2, 'multiplier': 1, 'num_INV': 2, 'num_SIB': 2}\")}>, 'feature_provenance': <FeatureProvenance[edit_seq] set()>, 'granularity': 'word'}>,\n",
       " <LeRecord:\n",
       " \t text=\"it 's robert duvall !\",\n",
       " \t target=\"[0.25, 0.75]\",\n",
       " \t le_attrs={'transformation_provenance': <TransformationProvenance: {(0, \"{'class': 'SibylTransformer', 'task': 'sentiment', 'num_classes': 2, 'multiplier': 1, 'num_INV': 2, 'num_SIB': 2}\")}>, 'feature_provenance': <FeatureProvenance[edit_seq] set()>, 'granularity': 'word'}>,\n",
       " <LeRecord:\n",
       " \t text=\"rich and sudden wisdom\",\n",
       " \t target=\"[0.25, 0.75]\",\n",
       " \t le_attrs={'transformation_provenance': <TransformationProvenance: {(0, \"{'class': 'SibylTransformer', 'task': 'sentiment', 'num_classes': 2, 'multiplier': 1, 'num_INV': 2, 'num_SIB': 2}\")}>, 'feature_provenance': <FeatureProvenance[edit_seq] set()>, 'granularity': 'word'}>,\n",
       " <LeRecord:\n",
       " \t text=\"acted and directed , it 's clear that washington most certainly has a new career ahead of him\",\n",
       " \t target=\"[0.25, 0.75]\",\n",
       " \t le_attrs={'transformation_provenance': <TransformationProvenance: {(0, \"{'class': 'SibylTransformer', 'task': 'sentiment', 'num_classes': 2, 'multiplier': 1, 'num_INV': 2, 'num_SIB': 2}\")}>, 'feature_provenance': <FeatureProvenance[edit_seq] set()>, 'granularity': 'word'}>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_records"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dpml",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
